{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a6a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (2.1.5)\n",
      "Requirement already satisfied: langsmith in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (0.3.44)\n",
      "Requirement already satisfied: PyMuPDF in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (1.26.0)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langsmith) (3.10.18)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from langsmith) (24.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langsmith) (0.23.0)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.7-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.6.2-cp312-cp312-win_amd64.whl.metadata (17 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.4.4-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.0rc1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\chari\\miniconda3\\envs\\ai_pro\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 24.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.7-cp312-cp312-win_amd64.whl (445 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.2-cp312-cp312-win_amd64.whl (45 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.4.4-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.7 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.6.2 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 propcache-0.3.1 pydantic-settings-2.9.1 typing-inspect-0.9.0 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "# ! pip install langchain langchain-google-genai langsmith PyMuPDF\n",
    "! pip install langchain langchain-google-genai langsmith PyMuPDF langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16d27078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60f0b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Set up API keys and environment variables ----\n",
    "# Replace with your actual keys\n",
    "os.environ[\"GOOGLE_API_KEY\"] = open(\"api_key_paid.txt\").read().strip()\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"ai-tutur-cg\"  # or your project name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "255dcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2. PDF to Chunks ----\n",
    "def langchain_load_and_chunk(pdf_path, chunk_size=1200, chunk_overlap=200):\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80b323be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---- 3. Build Prompt Template ----\n",
    "prompt_template = \"\"\"\n",
    "You are an expert curriculum designer.\n",
    "Given these document chunks, generate a Learning Path structure in JSON format.\n",
    "\n",
    "Format Example:\n",
    "{{\n",
    "  \"sections\": [\n",
    "    {{\n",
    "      \"section_id\": \"S1\",\n",
    "      \"title\": \"<Section Title>\",\n",
    "      \"brief\": \"<Short 2–3 line description>\",\n",
    "      \"subsections\": [\n",
    "        {{\n",
    "          \"subsection_id\": \"S1.1\",\n",
    "          \"title\": \"<Subsection Title>\",\n",
    "          \"sub_titles\": [\"<Sub-title 1>\", \"<Sub-title 2>\"],  // Use [] if none\n",
    "          \"brief\": \"<Short 2–3 line description>\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "For each subsection, include a 'sub_titles' list with relevant sub-headings found in the chunk (use an empty list [] if none are present). Always include the 'brief' field with a 2–3 line summary.\n",
    "\n",
    "Document Chunks:\n",
    "{chunks}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# prompt_template = \"\"\"\n",
    "# You are an expert curriculum designer.\n",
    "# Given these document chunks, generate a Learning Path structure in JSON format.\n",
    "\n",
    "# Format Example:\n",
    "# {{\n",
    "#   \"sections\": [\n",
    "#     {{\n",
    "#       \"section_id\": \"S1\",\n",
    "#       \"title\": \"<Section Title>\",\n",
    "#       \"brief\": \"<Short 2–3 line description>\",\n",
    "#       \"subsections\": [\n",
    "#         {{\n",
    "#           \"subsection_id\": \"S1.1\",\n",
    "#           \"title\": \"<Subsection Title>\",\n",
    "#           \"sub_titles\": [\"<Sub-title 1>\", \"<Sub-title 2>\"],  // Use [] if none\n",
    "#           \"brief\": \"<Short 2–3 line description>\"\n",
    "#         }}\n",
    "#       ]\n",
    "#     }}\n",
    "#   ]\n",
    "# }}\n",
    "\n",
    "# For each subsection, include a 'sub_titles' list with relevant sub-headings found in the chunk (use an empty list [] if none are present).\n",
    "# **Sort the sub_titles list in the logical order a student should learn them, from foundational concepts to more advanced or specific topics.**  # NEW\n",
    "# Always include the 'brief' field with a 2–3 line summary.\n",
    "\n",
    "# Document Chunks:\n",
    "# {chunks}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b07c9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 4. Set up Gemini Model ----\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-pro-latest\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bde21760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 5. Agent Orchestrator ----\n",
    "def run_langchain_structuring_agent(pdf_path):\n",
    "    print(\"Loading and splitting document...\")\n",
    "    docs = langchain_load_and_chunk(pdf_path)\n",
    "    chunk_texts = \"\\n\\n\".join([doc.page_content[:800] for doc in docs])  # Use only first 800 chars per chunk for prompt size\n",
    "\n",
    "    chain = (\n",
    "        prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    print(\"\\nPrompt preview (truncated):\\n\", prompt.format(chunks=chunk_texts)[:1200], \"\\n...\")\n",
    "    print(\"\\nCalling Gemini via LangChain...\\n\")\n",
    "    output = chain.invoke({\"chunks\": chunk_texts})\n",
    "\n",
    "    try:\n",
    "        skeleton = json.loads(output)\n",
    "        print(json.dumps(skeleton, indent=2, ensure_ascii=False))\n",
    "        with open(\"learning_path_skeleton.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(skeleton, f, indent=2, ensure_ascii=False)\n",
    "        print(\"\\n✅ Learning Skeleton saved as 'learning_path_skeleton.json'\")\n",
    "    except Exception:\n",
    "        print(\"\\nGemini output was not valid JSON. Here is the raw output:\\n\")\n",
    "        print(output)\n",
    "        skeleton = None\n",
    "    return skeleton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74c6dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and splitting document...\n",
      "\n",
      "Prompt preview (truncated):\n",
      " \n",
      "You are an expert curriculum designer.\n",
      "Given these document chunks, generate a Learning Path structure in JSON format.\n",
      "\n",
      "Format Example:\n",
      "{\n",
      "  \"sections\": [\n",
      "    {\n",
      "      \"section_id\": \"S1\",\n",
      "      \"title\": \"<Section Title>\",\n",
      "      \"brief\": \"<Short 2–3 line description>\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S1.1\",\n",
      "          \"title\": \"<Subsection Title>\",\n",
      "          \"sub_titles\": [\"<Sub-title 1>\", \"<Sub-title 2>\"],  // Use [] if none\n",
      "          \"brief\": \"<Short 2–3 line description>\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "For each subsection, include a 'sub_titles' list with relevant sub-headings found in the chunk (use an empty list [] if none are present). Always include the 'brief' field with a 2–3 line summary.\n",
      "\n",
      "Document Chunks:\n",
      "INTRODUCTION\n",
      "TO\n",
      "MACHINE LEARNING\n",
      "AN EARLY DRAFT OF A PROPOSED\n",
      "TEXTBOOK\n",
      "Nils J. Nilsson\n",
      "Robotics Laboratory\n",
      "Department of Computer Science\n",
      "Stanford University\n",
      "Stanford, CA 94305\n",
      "e-mail: nilsson@cs.stanford.edu\n",
      "November 3, 1998\n",
      "Copyright c⃝2005 Nils J. Nilsson\n",
      "This material may not be copied, reproduced, or distributed without the\n",
      "written permission of the copyright holder.\n",
      "\n",
      "ii\n",
      "\n",
      "Contents\n",
      "1\n",
      "Preliminaries\n",
      "1\n",
      "1.1\n",
      "Introduction . . . . . . . . . . . .  \n",
      "...\n",
      "\n",
      "Calling Gemini via LangChain...\n",
      "\n",
      "\n",
      "Gemini output was not valid JSON. Here is the raw output:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"sections\": [\n",
      "    {\n",
      "      \"section_id\": \"S1\",\n",
      "      \"title\": \"Preliminaries\",\n",
      "      \"brief\": \"This section introduces the concept of machine learning, its various forms (supervised, unsupervised), and the importance of bias in learning. It also discusses training regimes, noise, performance evaluation, and provides a glimpse into real-world applications.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S1.1\",\n",
      "          \"title\": \"Introduction\",\n",
      "          \"sub_titles\": [\"What is Machine Learning?\", \"Wellsprings of Machine Learning\", \"Varieties of Machine Learning\"],\n",
      "          \"brief\": \"This subsection defines machine learning, explores its origins in different fields like statistics, brain models, and AI, and discusses the various types of computational structures that can be learned.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S1.2\",\n",
      "          \"title\": \"Learning Input-Output Functions\",\n",
      "          \"sub_titles\": [\"Types of Learning\", \"Input Vectors\", \"Outputs\", \"Training Regimes\", \"Noise\", \"Performance Evaluation\"],\n",
      "          \"brief\": \"This subsection details the process of learning input-output functions, including the types of input and output values, different training methods (batch, incremental, online), the impact of noise, and how performance is evaluated.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S1.3\",\n",
      "          \"title\": \"Learning Requires Bias\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection explains why bias is essential for learning and generalization, differentiating between absolute bias and preference bias.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S1.4\",\n",
      "          \"title\": \"Sample Applications\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection provides a brief overview of real-world applications of machine learning in various domains.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S1.5\",\n",
      "          \"title\": \"Sources\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection lists resources for further exploration of machine learning, including textbooks and conferences.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S1.6\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S2\",\n",
      "      \"title\": \"Boolean Functions\",\n",
      "      \"brief\": \"This section provides a detailed overview of Boolean functions, their representations, and important subclasses, laying the groundwork for understanding their role in machine learning.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S2.1\",\n",
      "          \"title\": \"Representation\",\n",
      "          \"sub_titles\": [\"Boolean Algebra\", \"Diagrammatic Representations\"],\n",
      "          \"brief\": \"This subsection explains how Boolean functions are represented using Boolean algebra and diagrammatic methods like hypercubes and Karnaugh maps.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S2.2\",\n",
      "          \"title\": \"Classes of Boolean Functions\",\n",
      "          \"sub_titles\": [\"Terms and Clauses\", \"DNF Functions\", \"CNF Functions\", \"Decision Lists\", \"Symmetric and Voting Functions\", \"Linearly Separable Functions\"],\n",
      "          \"brief\": \"This subsection introduces important subclasses of Boolean functions, including terms, clauses, DNF, CNF, decision lists, symmetric functions, and linearly separable functions, discussing their properties and relationships.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S2.3\",\n",
      "          \"title\": \"Summary\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection summarizes the different classes of Boolean functions and their set inclusions.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S2.4\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S3\",\n",
      "      \"title\": \"Using Version Spaces for Learning\",\n",
      "      \"brief\": \"This section introduces the concept of version spaces and version graphs for learning Boolean functions, providing a theoretical framework for understanding hypothesis selection.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S3.1\",\n",
      "          \"title\": \"Version Spaces and Mistake Bounds\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection defines version spaces and explains how they are used to represent consistent hypotheses, introducing the concept of mistake bounds.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S3.2\",\n",
      "          \"title\": \"Version Graphs\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection introduces version graphs as a way to visually represent the generality/specificity relationships between hypotheses in a version space, explaining the concept of boundary sets.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S3.3\",\n",
      "          \"title\": \"Learning as Search of a Version Space\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection frames learning as a search problem within a version space.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S3.4\",\n",
      "          \"title\": \"The Candidate Elimination Method\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection describes the candidate elimination algorithm for incrementally computing boundary sets of a version space.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S3.5\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S4\",\n",
      "      \"title\": \"Neural Networks\",\n",
      "      \"brief\": \"This section explores the use of neural networks, specifically networks of Threshold Logic Units (TLUs), for implementing and training input-output functions.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S4.1\",\n",
      "          \"title\": \"Threshold Logic Units\",\n",
      "          \"sub_titles\": [\"Definitions and Geometry\", \"Special Cases of Linearly Separable Functions\", \"Error-Correction Training of a TLU\", \"Weight Space\", \"The Widrow-Hoﬀ Procedure\"],\n",
      "          \"brief\": \"This subsection introduces TLUs, their geometric interpretation, how they implement specific Boolean functions, and training methods like error-correction and Widrow-Hoﬀ.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S4.2\",\n",
      "          \"title\": \"Linear Machines\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection introduces linear machines as a generalization of TLUs for multi-category classification.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S4.3\",\n",
      "          \"title\": \"Networks of TLUs\",\n",
      "          \"sub_titles\": [\"Motivation and Examples\", \"Madalines\", \"Piecewise Linear Machines\", \"Cascade Networks\"],\n",
      "          \"brief\": \"This subsection explores networks of TLUs, including layered feedforward networks, Madalines, piecewise linear machines, and cascade networks, discussing their architectures and training methods.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S4.4\",\n",
      "          \"title\": \"Training Feedforward Networks by Backpropagation\",\n",
      "          \"sub_titles\": [\"Notation\", \"The Backpropagation Method\", \"Computing Weight Changes in the Final Layer\", \"Computing Changes to the Weights in Intermediate Layers\", \"Variations on Backprop\", \"An Application: Steering a Van\"],\n",
      "          \"brief\": \"This subsection details the backpropagation algorithm for training multilayer feedforward networks, including its derivation, variations, and a practical application example.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S4.5\",\n",
      "          \"title\": \"Synergies Between Neural Network and Knowledge-Based Methods\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection discusses the potential for combining neural networks with knowledge-based methods.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S5\",\n",
      "      \"title\": \"Statistical Learning\",\n",
      "      \"brief\": \"This section introduces statistical methods for learning, focusing on decision theory, Gaussian distributions, and nearest-neighbor methods.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S5.1\",\n",
      "          \"title\": \"Using Statistical Decision Theory\",\n",
      "          \"sub_titles\": [\"Background and General Method\", \"Gaussian (or Normal) Distributions\", \"Conditionally Independent Binary Components\"],\n",
      "          \"brief\": \"This subsection explains how statistical decision theory can be used for classification, including the use of Gaussian distributions and the case of conditionally independent binary components.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S5.2\",\n",
      "          \"title\": \"Learning Belief Networks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for learning belief networks.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S5.3\",\n",
      "          \"title\": \"Nearest-Neighbor Methods\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection describes nearest-neighbor methods for classification, including distance metrics and performance considerations.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S5.4\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S6\",\n",
      "      \"title\": \"Decision Trees\",\n",
      "      \"brief\": \"This section covers decision trees, their use in classification, learning algorithms, and methods to address overfitting.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S6.1\",\n",
      "          \"title\": \"Definitions\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection defines decision trees and their components, including tests and leaf nodes.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S6.2\",\n",
      "          \"title\": \"Supervised Learning of Univariate Decision Trees\",\n",
      "          \"sub_titles\": [\"Selecting the Type of Test\", \"Using Uncertainty Reduction to Select Tests\", \"Non-Binary Attributes\"],\n",
      "          \"brief\": \"This subsection explains how to learn univariate decision trees using supervised learning, focusing on uncertainty reduction as a criterion for selecting tests.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S6.3\",\n",
      "          \"title\": \"Networks Equivalent to Decision Trees\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection shows the equivalence between decision trees and certain types of neural networks.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S6.4\",\n",
      "          \"title\": \"Overfitting and Evaluation\",\n",
      "          \"sub_titles\": [\"Overfitting\", \"Validation Methods\", \"Avoiding Overfitting in Decision Trees\", \"Minimum-Description Length Methods\"],\n",
      "          \"brief\": \"This subsection discusses the problem of overfitting in decision trees and methods to avoid it, including validation techniques and minimum-description length methods.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S6.5\",\n",
      "          \"title\": \"The Problem of Replicated Subtrees\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection discusses the problem of replicated subtrees in decision trees and methods to address it, such as decision graphs and multivariate tests.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S6.6\",\n",
      "          \"title\": \"The Problem of Missing Attributes\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for handling missing attributes in decision trees.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S6.7\",\n",
      "          \"title\": \"Comparisons\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection compares decision trees with other classifiers like neural networks and nearest-neighbor methods.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S6.8\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S7\",\n",
      "      \"title\": \"Inductive Logic Programming\",\n",
      "      \"brief\": \"This section introduces inductive logic programming (ILP) for learning logic programs from examples and background knowledge.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S7.1\",\n",
      "          \"title\": \"Notation and Definitions\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection introduces the notation and definitions used in ILP, including the concepts of covering, sufficiency, necessity, and consistency of logic programs.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S7.2\",\n",
      "          \"title\": \"A Generic ILP Algorithm\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection presents a generic algorithm for inducing logic programs from examples and background knowledge.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S7.3\",\n",
      "          \"title\": \"An Example\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection provides a detailed example of applying the generic ILP algorithm to learn a logic program for an airline route problem.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S7.4\",\n",
      "          \"title\": \"Inducing Recursive Programs\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection extends the ILP algorithm to handle recursive programs, illustrating the process with an example.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S7.5\",\n",
      "          \"title\": \"Choosing Literals to Add\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection discusses strategies for selecting literals to add to clauses during the ILP process, focusing on information-like measures.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S7.6\",\n",
      "          \"title\": \"Relationships Between ILP and Decision Tree Induction\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection explains the connection between ILP and decision tree induction, framing ILP as a form of multivariate decision tree learning.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S7.7\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S8\",\n",
      "      \"title\": \"Computational Learning Theory\",\n",
      "      \"brief\": \"This section delves into the theoretical foundations of learning, focusing on Probably Approximately Correct (PAC) learning and the Vapnik-Chervonenkis (VC) dimension.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S8.1\",\n",
      "          \"title\": \"Notation and Assumptions for PAC Learning Theory\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection introduces the notation and assumptions used in PAC learning theory, including target functions, hypotheses, error, and PAC learnability.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S8.2\",\n",
      "          \"title\": \"PAC Learning\",\n",
      "          \"sub_titles\": [\"The Fundamental Theorem\", \"Examples\", \"Some Properly PAC-Learnable Classes\"],\n",
      "          \"brief\": \"This subsection presents the fundamental theorem of PAC learning, provides examples of PAC learnable classes, and discusses the concept of properly PAC learnable classes.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S8.3\",\n",
      "          \"title\": \"The Vapnik-Chervonenkis Dimension\",\n",
      "          \"sub_titles\": [\"Linear Dichotomies\", \"Capacity\", \"A More General Capacity Result\", \"Some Facts and Speculations About the VC Dimension\"],\n",
      "          \"brief\": \"This subsection introduces the VC dimension as a measure of the expressive power of a hypothesis set, discussing its relationship to linear dichotomies and capacity.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S8.4\",\n",
      "          \"title\": \"VC Dimension and PAC Learning\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection connects the VC dimension with PAC learning, presenting theorems that relate the two concepts.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S8.5\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S9\",\n",
      "      \"title\": \"Unsupervised Learning\",\n",
      "      \"brief\": \"This section explores unsupervised learning methods for finding natural partitions and hierarchies in unlabeled data.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S9.1\",\n",
      "          \"title\": \"What is Unsupervised Learning?\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection defines unsupervised learning and its two main stages: partitioning into clusters and designing a classifier based on the clusters.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S9.2\",\n",
      "          \"title\": \"Clustering Methods\",\n",
      "          \"sub_titles\": [\"A Method Based on Euclidean Distance\", \"A Method Based on Probabilities\"],\n",
      "          \"brief\": \"This subsection describes two clustering methods, one based on Euclidean distance and the other on probabilities.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S9.3\",\n",
      "          \"title\": \"Hierarchical Clustering Methods\",\n",
      "          \"sub_titles\": [\"A Method Based on Euclidean Distance\", \"A Method Based on Probabilities\"],\n",
      "          \"brief\": \"This subsection describes two hierarchical clustering methods, one based on Euclidean distance and the other on probabilities.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S9.4\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S10\",\n",
      "      \"title\": \"Temporal-Difference Learning\",\n",
      "      \"brief\": \"This section introduces temporal-difference (TD) learning for predicting future values in temporal sequences.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S10.1\",\n",
      "          \"title\": \"Temporal Patterns and Prediction Problems\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection introduces the concept of temporal patterns and prediction problems, distinguishing between single-step and multi-step prediction.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S10.2\",\n",
      "          \"title\": \"Supervised and Temporal-Difference Methods\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection compares supervised learning with TD learning, explaining the TD(λ) family of methods.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S10.3\",\n",
      "          \"title\": \"Incremental Computation of the (∆W)i\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection describes how to compute weight updates incrementally in TD learning.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S10.4\",\n",
      "          \"title\": \"An Experiment with TD Methods\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection presents an experiment comparing different TD(λ) methods on a Markov process.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S10.5\",\n",
      "          \"title\": \"Theoretical Results\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection presents theoretical results on the convergence of TD methods.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S10.6\",\n",
      "          \"title\": \"Intra-Sequence Weight Updating\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection discusses weight updating within a sequence in TD learning.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S10.7\",\n",
      "          \"title\": \"An Example Application: TD-gammon\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection describes the TD-gammon program, which uses TD learning to play backgammon.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S10.8\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S11\",\n",
      "      \"title\": \"Delayed-Reinforcement Learning\",\n",
      "      \"brief\": \"This section explores delayed-reinforcement learning, where an agent learns to maximize rewards over time through trial and error.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S11.1\",\n",
      "          \"title\": \"The General Problem\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection introduces the general problem of delayed-reinforcement learning, where an agent learns a policy to maximize rewards in an unknown environment.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S11.2\",\n",
      "          \"title\": \"An Example\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection provides an example of delayed-reinforcement learning in a grid world.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S11.3\",\n",
      "          \"title\": \"Temporal Discounting and Optimal Policies\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection discusses temporal discounting and the concept of optimal policies in reinforcement learning.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S11.4\",\n",
      "          \"title\": \"Q-Learning\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection introduces Q-learning, a TD(0) method for learning optimal Q values.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S11.5\",\n",
      "          \"title\": \"Discussion, Limitations, and Extensions of Q-Learning\",\n",
      "          \"sub_titles\": [\"An Illustrative Example\", \"Using Random Actions\", \"Generalizing Over Inputs\", \"Partially Observable States\", \"Scaling Problems\"],\n",
      "          \"brief\": \"This subsection discusses various aspects of Q-learning, including an example, exploration strategies, generalization, partially observable states, and scaling problems.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S11.6\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"S12\",\n",
      "      \"title\": \"Explanation-Based Learning\",\n",
      "      \"brief\": \"This section introduces explanation-based learning (EBL) for converting implicit knowledge into explicit knowledge.\",\n",
      "      \"subsections\": [\n",
      "        {\n",
      "          \"subsection_id\": \"S12.1\",\n",
      "          \"title\": \"Deductive Learning\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection introduces deductive learning and contrasts it with inductive learning.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S12.2\",\n",
      "          \"title\": \"Domain Theories\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection explains the concept of domain theories in EBL.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S12.3\",\n",
      "          \"title\": \"An Example\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection provides an example of EBL applied to the concept of robot robustness.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S12.4\",\n",
      "          \"title\": \"Evaluable Predicates\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection discusses the concept of evaluable predicates in EBL.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S12.5\",\n",
      "          \"title\": \"More General Proofs\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection discusses the generalization of proofs in EBL.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S12.6\",\n",
      "          \"title\": \"Utility of EBL\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"This subsection discusses the utility and limitations of EBL.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S12.7\",\n",
      "          \"title\": \"Applications\",\n",
      "          \"sub_titles\": [\"Macro-Operators in Planning\", \"Learning Search Control Knowledge\"],\n",
      "          \"brief\": \"This subsection discusses applications of EBL, including macro-operators in planning and learning search control knowledge.\"\n",
      "        },\n",
      "        {\n",
      "          \"subsection_id\": \"S12.8\",\n",
      "          \"title\": \"Bibliographical and Historical Remarks\",\n",
      "          \"sub_titles\": [],\n",
      "          \"brief\": \"Placeholder for historical context and references.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ---- 6. Example Usage ----\n",
    "run_langchain_structuring_agent(\"mi-intro.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf0c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fde50f8",
   "metadata": {},
   "source": [
    "# ðŸ““ 0. Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c94af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q python-dotenv haystack-ai==2.2.4 haystack-experimental==0.1.0 google-generativeai pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chari\\miniconda3\\envs\\ai_pro\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from haystack import Pipeline, Document, component\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.preprocessors.document_splitter import DocumentSplitter\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "MODEL_NAME = \"gemini-2.0-flash\"\n",
    "PAID_MODE = True\n",
    "\n",
    "def configure_gemini():\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    model = genai.GenerativeModel(model_name=MODEL_NAME)\n",
    "    return model\n",
    "\n",
    "model = configure_gemini()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299fca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 11. TaskManagerAgent & UsageTrackerAgent (Utilities Setup)\n",
    "# =============================================\n",
    "\n",
    "def estimate_tokens(text):\n",
    "    return max(1, len(text) // 4)\n",
    "\n",
    "def estimate_output_tokens(text):\n",
    "    return max(1, len(text) // 4)\n",
    "\n",
    "def load_usage(usage_file=\"gemini_usage.json\"):\n",
    "    if os.path.exists(usage_file):\n",
    "        with open(usage_file, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return {\n",
    "        'date': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'minute': datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        'requests_today': 0,\n",
    "        'requests_this_minute': 0,\n",
    "        'tokens_this_minute': 0,\n",
    "        'input_tokens_today': 0,\n",
    "        'output_tokens_today': 0,\n",
    "        'total_cost_today': 0.0\n",
    "    }\n",
    "\n",
    "def save_usage(usage, usage_file=\"gemini_usage.json\"):\n",
    "    with open(usage_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(usage, f, indent=2)\n",
    "\n",
    "def update_usage(usage, input_tokens, output_tokens, usage_file=\"gemini_usage.json\", cost=None):\n",
    "    now = datetime.now()\n",
    "    today = now.strftime('%Y-%m-%d')\n",
    "    this_minute = now.strftime('%Y-%m-%d %H:%M')\n",
    "    if usage['date'] != today:\n",
    "        usage['date'] = today\n",
    "        usage['requests_today'] = 0\n",
    "        usage['input_tokens_today'] = 0\n",
    "        usage['output_tokens_today'] = 0\n",
    "        usage['total_cost_today'] = 0.0\n",
    "    if usage['minute'] != this_minute:\n",
    "        usage['minute'] = this_minute\n",
    "        usage['requests_this_minute'] = 0\n",
    "        usage['tokens_this_minute'] = 0\n",
    "    usage['requests_today'] += 1\n",
    "    usage['requests_this_minute'] += 1\n",
    "    usage['tokens_this_minute'] += input_tokens\n",
    "    usage['input_tokens_today'] += input_tokens\n",
    "    usage['output_tokens_today'] += output_tokens\n",
    "    if 'total_cost_today' not in usage:\n",
    "        usage['total_cost_today'] = 0.0\n",
    "    if cost is not None:\n",
    "        usage['total_cost_today'] += cost\n",
    "    save_usage(usage, usage_file)\n",
    "    return usage\n",
    "\n",
    "def enforce_limits(usage, paid_mode=False, free_rpm=15, free_tpm=1_000_000):\n",
    "    if usage['requests_today'] >= 1500:\n",
    "        msg = f\"Daily request limit (1500) reached.\"\n",
    "        if paid_mode:\n",
    "            print(f\"WARNING: {msg}\")\n",
    "        else:\n",
    "            print(f\"{msg} Exiting.\")\n",
    "            exit(1)\n",
    "\n",
    "    if usage['requests_this_minute'] >= free_rpm:\n",
    "        msg = f\"Minute request limit ({free_rpm}) reached.\"\n",
    "        if paid_mode:\n",
    "            print(f\"WARNING: {msg}\")\n",
    "        else:\n",
    "            print(f\"{msg} Waiting...\")\n",
    "            while True:\n",
    "                time.sleep(1)\n",
    "                now = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "                if now != usage['minute']:\n",
    "                    break\n",
    "\n",
    "    if usage['tokens_this_minute'] >= free_tpm:\n",
    "        msg = f\"Minute token limit ({free_tpm}) reached.\"\n",
    "        if paid_mode:\n",
    "            print(f\"WARNING: {msg}\")\n",
    "        else:\n",
    "            print(f\"{msg} Waiting...\")\n",
    "            while True:\n",
    "                time.sleep(1)\n",
    "                now = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "                if now != usage['minute']:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f91542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Load API key from file and configure Gemini\n",
    "with open(\"api_key_paid.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6cdf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Gemini to generate Learning Skeleton...\n",
      "Gemini response was not valid JSON. Printing raw output:\n",
      "Okay, I'm ready. Please provide the document chunks you want me to use to generate the Learning Path structure in JSON format. I will analyze the chunks and create a logical learning progression with appropriate sections, subsections, titles, and briefs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 1. StructuringAgent â€“ Building Learning Skeleton\n",
    "# =============================================\n",
    "\n",
    "# Create Ingestion Pipeline\n",
    "def create_ingestion_pipeline():\n",
    "    document_store = InMemoryDocumentStore()\n",
    "    pdf_converter = PyPDFToDocument()\n",
    "    splitter = DocumentSplitter(split_by=\"word\", split_length=300, split_overlap=50)\n",
    "    writer = DocumentWriter(document_store=document_store)\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.add_component(\"converter\", pdf_converter)\n",
    "    pipeline.add_component(\"splitter\", splitter)\n",
    "    pipeline.add_component(\"writer\", writer)\n",
    "\n",
    "    pipeline.connect(\"converter\", \"splitter\")\n",
    "    pipeline.connect(\"splitter\", \"writer\")\n",
    "\n",
    "    return pipeline, document_store\n",
    "\n",
    "# Build Prompt for Learning Skeleton\n",
    "def build_learning_skeleton_prompt():\n",
    "    prompt_template = \"\"\"\n",
    "    You are an expert curriculum designer.\n",
    "    Given extracted document chunks, generate a Learning Path structure:\n",
    "\n",
    "    JSON Format Only:\n",
    "    {\n",
    "      \"sections\": [\n",
    "        {\n",
    "          \"section_id\": \"S1\",\n",
    "          \"title\": \"<Section Title>\",\n",
    "          \"brief\": \"<Short 2â€“3 line description>\",\n",
    "          \"subsections\": [\n",
    "            {\n",
    "              \"subsection_id\": \"S1.1\",\n",
    "              \"title\": \"<Subsection Title>\",\n",
    "              \"brief\": \"<Short 2â€“3 line description>\"\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "\n",
    "    Chunks:\n",
    "    {% for document in documents %}\n",
    "    {{ document.content }}\n",
    "    {% endfor %}\n",
    "    \"\"\"\n",
    "    return PromptBuilder(template=prompt_template)\n",
    "\n",
    "# Call Gemini to generate learning skeleton\n",
    "def call_gemini_learning_skeleton(prompt_text, usage_file=\"gemini_usage.json\"):\n",
    "    usage = load_usage(usage_file)\n",
    "    enforce_limits(usage, paid_mode=PAID_MODE)\n",
    "    time.sleep(4)  # Smart delay for free tier\n",
    "    response = model.generate_content(prompt_text)\n",
    "    output_text = response.text\n",
    "    track_and_update_usage(prompt_text, output_text, usage_file, paid_mode=PAID_MODE)\n",
    "    return output_text\n",
    "\n",
    "def track_and_update_usage(prompt_text, output_text, usage_file=\"gemini_usage.json\", paid_mode=True):\n",
    "    input_tokens = estimate_tokens(prompt_text)\n",
    "    output_tokens = estimate_output_tokens(output_text)\n",
    "\n",
    "    if paid_mode:\n",
    "        pricing = {'input': 0.15/1_000_000, 'output': 0.60/1_000_000}\n",
    "    else:\n",
    "        pricing = {'input': 0.0, 'output': 0.0}\n",
    "\n",
    "    cost = input_tokens * pricing['input'] + output_tokens * pricing['output']\n",
    "    usage = load_usage(usage_file)\n",
    "    update_usage(usage, input_tokens, output_tokens, usage_file, cost)\n",
    "\n",
    "# Run StructuringAgent\n",
    "def run_structuring_agent(pdf_path):\n",
    "    ingestion_pipeline, document_store = create_ingestion_pipeline()\n",
    "    ingestion_pipeline.run({\"converter\": {\"sources\": [pdf_path]}})\n",
    "    all_documents = document_store.filter_documents()\n",
    "\n",
    "    prompt_builder = build_learning_skeleton_prompt()\n",
    "    prompt = prompt_builder.run({\"documents\": all_documents})[\"prompt\"]\n",
    "\n",
    "    print(\"Calling Gemini to generate Learning Skeleton...\")\n",
    "    gemini_response = call_gemini_learning_skeleton(prompt)\n",
    "\n",
    "    try:\n",
    "        structured_output = json.loads(gemini_response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Gemini response was not valid JSON. Printing raw output:\")\n",
    "        print(gemini_response)\n",
    "        return None\n",
    "\n",
    "    print(json.dumps(structured_output, indent=2, ensure_ascii=False))\n",
    "\n",
    "    with open(\"learning_path_skeleton.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(structured_output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"âœ… Learning Skeleton saved as 'learning_path_skeleton.json'\")\n",
    "    return structured_output\n",
    "\n",
    "# Example usage (uncomment to test):\n",
    "run_structuring_agent(\"mi-intro.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 2. ContentExtractionAgent â€“ Retrieving Full Detailed Content\n",
    "# =============================================\n",
    "\n",
    "def run_content_extraction_agent(document_store, skeleton_json_path=\"learning_path_skeleton.json\"):\n",
    "    print(\"ðŸ”² ContentExtractionAgent is a placeholder for now.\")\n",
    "    print(\"Will retrieve detailed content for each section/subsection based on skeleton.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48309e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 3. ContentSkillAssessorAgent (First Round)\n",
    "# =============================================\n",
    "\n",
    "def run_content_skill_assessor_agent():\n",
    "    print(\"ðŸ”² ContentSkillAssessorAgent is a placeholder for now.\")\n",
    "    print(\"Will generate pre-learning content skill assessments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 4. AptitudeSkillAssessorAgent\n",
    "# =============================================\n",
    "\n",
    "def run_aptitude_skill_assessor_agent():\n",
    "    print(\"ðŸ”² AptitudeSkillAssessorAgent is a placeholder for now.\")\n",
    "    print(\"Will create aptitude tests independent of content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 5. CustomizedLearningPathAgent (First Pass)\n",
    "# =============================================\n",
    "\n",
    "def run_customized_learning_path_agent():\n",
    "    print(\"ðŸ”² CustomizedLearningPathAgent is a placeholder for now.\")\n",
    "    print(\"Will create a customized learning path based on content + aptitude assessment results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 6. QuizAgent\n",
    "# =============================================\n",
    "\n",
    "def run_quiz_agent():\n",
    "    print(\"ðŸ”² QuizAgent is a placeholder for now.\")\n",
    "    print(\"Will generate quizzes matching the user's skill level based on customized learning path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 7. TooltipAgent\n",
    "# =============================================\n",
    "\n",
    "def run_tooltip_agent():\n",
    "    print(\"ðŸ”² TooltipAgent is a placeholder for now.\")\n",
    "    print(\"Will create glossary tooltips for important terms based on the customized learning path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 8. AssistantAgent\n",
    "# =============================================\n",
    "\n",
    "def run_assistant_agent():\n",
    "    print(\"ðŸ”² AssistantAgent is a placeholder for now.\")\n",
    "    print(\"Will create a Section-specific Q&A chatbot to assist the user during learning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689019dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 9. ContentSkillAssessorAgent (Reassessment Round)\n",
    "# =============================================\n",
    "\n",
    "def run_content_skill_reassessor_agent():\n",
    "    print(\"ðŸ”² ContentSkillAssessorAgent (Reassessment) is a placeholder for now.\")\n",
    "    print(\"Will reassess the user's mastery level after completing the first learning path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ðŸ““ 10. CustomizedLearningPathAgent (Iteration Phase)\n",
    "# =============================================\n",
    "\n",
    "def run_learning_path_iteration_agent():\n",
    "    print(\"ðŸ”² CustomizedLearningPathAgent (Iteration Phase) is a placeholder for now.\")\n",
    "    print(\"Will adapt and modify the learning path based on reassessment results if needed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
